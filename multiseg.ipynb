{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils import normalize\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tifffile as tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import transform, util\n",
    "from PIL import Image\n",
    "\n",
    "# Load the original images and masks\n",
    "images = []\n",
    "masks = []\n",
    "aug_masks = []\n",
    "# for i in range(1, 31):\n",
    "#     image = Image.open(f\"./PhC-C2DH-U373/aug/ori/imaging ({i}).tif\")\n",
    "#     mask = Image.open(f\"./PhC-C2DH-U373/aug/ori/segmentation ({i}).tif\")\n",
    "#     # resize image\n",
    "#     image = image.resize((512, 512))\n",
    "#     mask = mask.resize((512, 512))\n",
    "#     images.append(np.array(image))\n",
    "#     masks.append(np.array(mask))\n",
    "\n",
    "\n",
    "for i in range(1, 20):\n",
    "    image = Image.open(f\"./PhC-C2DH-U373/img/02 ({i}).tif\")\n",
    "    mask = Image.open(f\"./PhC-C2DH-U373/mask/02 ({i}).tif\")\n",
    "    # resize image\n",
    "    image = image.resize((512, 512))\n",
    "    mask = mask.resize((512, 512))\n",
    "    images.append(np.array(image))\n",
    "    masks.append(np.array(mask))\n",
    "\n",
    "print(len(images))\n",
    "print(np.unique(masks))\n",
    "\n",
    "# Define the data augmentation transformations\n",
    "# dont change the masks classes \n",
    "augmentations = [\n",
    "    # transform.flip,\n",
    "    transform.rotate,\n",
    "    # transform.rescale,\n",
    "    # transform.crop,\n",
    "    # util.random_noise\n",
    "]\n",
    "\n",
    "\n",
    "# for every image and mask, rotate it 90, 180, 270 degrees\n",
    "# for i in range(len(images)):\n",
    "#     image = images[i]\n",
    "#     mask = masks[i]\n",
    "#     for j in range(3):\n",
    "#         aug_image = transform.rotate(image, (j+1) * 90, preserve_range=True, order=0)\n",
    "#         aug_mask = transform.rotate(mask, (j+1) * 90, preserve_range=True, order=0)\n",
    "#         images.append(aug_image)\n",
    "#         masks.append(aug_mask)\n",
    "\n",
    "print(len(images))\n",
    "\n",
    "# save the augmented images and masks\n",
    "# for i in range(len(images)):\n",
    "#     Image.fromarray(images[i]).save(f\"./PhC-C2DH-U373/aug/img/augmented_image_{i}.tif\")\n",
    "#     Image.fromarray(masks[i]).save(f\"./PhC-C2DH-U373/aug/mask/augmented_mask_{i}.tif\")\n",
    "\n",
    "# Apply data augmentation to generate 200 new images and masks\n",
    "for i in range(100):\n",
    "    # Randomly select an image and mask from the original set\n",
    "    idx = np.random.randint(len(images))\n",
    "    image = images[idx]\n",
    "    mask = masks[idx]\n",
    "\n",
    "    # Apply a random data augmentation transformation to the image and mask\n",
    "    aug_idx = np.random.randint(len(augmentations))\n",
    "    aug_fn = augmentations[aug_idx]\n",
    "    # image = aug_fn(image)\n",
    "    # mask = aug_fn(mask)\n",
    "    if aug_idx == 0:\n",
    "        image = aug_fn(image, np.random.randint(1, 4) * 90, preserve_range=True, order=0)\n",
    "        mask = aug_fn(mask, np.random.randint(1, 4) * 90, preserve_range=True, order=0)\n",
    "    # elif aug_idx == 1:\n",
    "    #     image = aug_fn(image, np.random.uniform(0.5, 1.5), preserve_range=True, order=0)\n",
    "    #     mask = aug_fn(mask, np.random.uniform(0.5, 1.5), preserve_range=True, order=0)\n",
    "    # elif aug_idx == 2:\n",
    "    #     image = aug_fn(image, var=np.random.uniform(0, 0.1))\n",
    "    #     mask = aug_fn(mask, var=np.random.uniform(0, 0.1))\n",
    "    \n",
    "#     aug_masks.append(mask)\n",
    "#     # Save the new image and mask to file\n",
    "#     # Image.fromarray(image).save(f\"./PhC-C2DH-U373/aug/img/augmented_image_{i}.tif\")\n",
    "#     # Image.fromarray(mask).save(f\"./PhC-C2DH-U373/aug/mask/augmented_mask_{i}.tif\")\n",
    "\n",
    "print(len(np.unique(masks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing images, if needed\n",
    "SIZE_X = 256\n",
    "SIZE_Y = 256\n",
    "n_classes = 2 #Number of classes for segmentation\n",
    "num_images = 200  #Total 1600 available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "(30, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "image_names = glob.glob(\"./PhC-C2DH-U373/aug/*.png\")\n",
    "print(len(image_names))\n",
    "image_names.sort()\n",
    "image_names_subset = image_names[0:num_images]\n",
    "images = [cv2.imread(image, 0) for image in image_names_subset]\n",
    "# resize images\n",
    "images = [cv2.resize(image, (SIZE_X, SIZE_Y)) for image in images]\n",
    "\n",
    "# # read tiff images\n",
    "# images = tiff.imread(\"./sandstone_data_for_ML/data_for_3D_Unet/train_images_256_256_256.tif\")\n",
    "# # sort images by name\n",
    "# images.sort()\n",
    "\n",
    "# select first 200 images\n",
    "images = images[0:num_images]\n",
    "image_dataset = np.array(images)\n",
    "image_dataset = np.expand_dims(image_dataset, axis = 3)\n",
    "print(image_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "image_names = glob.glob(\"./PhC-C2DH-U373/label/*.png\")\n",
    "image_names.sort()\n",
    "image_names_subset = image_names[0:num_images]\n",
    "mask = [cv2.imread(image, 0) for image in image_names_subset]\n",
    "# resize images\n",
    "mask = [cv2.resize(image, (SIZE_X, SIZE_Y)) for image in mask]\n",
    "# read tiff images\n",
    "# mask = tiff.imread(\"./sandstone_data_for_ML/data_for_3D_Unet/train_masks_256_256_256.tif\")\n",
    "\n",
    "# mask.sort()\n",
    "mask_subset = mask[0:num_images]\n",
    "\n",
    "mask_dataset = np.array(mask_subset)\n",
    "\n",
    "# first normalize the mask\n",
    "mask_dataset = mask_dataset / 255\n",
    "# then devide the mask into 2 classes\n",
    "mask_dataset[mask_dataset > 0.5] = 1\n",
    "mask_dataset[mask_dataset <= 0.5] = 0\n",
    "\n",
    "# mask_dataset = np.expand_dims(mask_dataset, axis = 3)\n",
    "print(mask_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data shape is:  (30, 256, 256, 1)\n",
      "Mask data shape is:  (30, 256, 256)\n",
      "Max pixel value in image is:  255\n",
      "Labels in the mask are :  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Image data shape is: \", image_dataset.shape)\n",
    "print(\"Mask data shape is: \", mask_dataset.shape)\n",
    "print(\"Max pixel value in image is: \", image_dataset.max())\n",
    "print(\"Labels in the mask are : \", len(np.unique(mask_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data augmentation\n",
    "# import elasticdeform\n",
    "# sigma = 30  # the standard deviation of the Gaussian filter\n",
    "# alpha = 50  # the intensity of the deformation\n",
    "# deformed_image = elasticdeform.deform_grid(image_dataset, sigma=sigma, alpha=alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode labels to 0, 1, 2, 3, ... but multi dim array so need to flatten, encode and reshape\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = mask_dataset.shape  \n",
    "mask_dataset_reshaped = mask_dataset.reshape(-1,1)\n",
    "mask_dataset_reshaped_encoded = labelencoder.fit_transform(mask_dataset_reshaped)\n",
    "mask_dataset_encoded = mask_dataset_reshaped_encoded.reshape(n, h, w)\n",
    "\n",
    "np.unique(mask_dataset_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "mask_dataset_encoded = np.expand_dims(mask_dataset_encoded, axis = 3)\n",
    "print(mask_dataset_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize images\n",
    "image_dataset = image_dataset /255.  #Can also normalize or scale using MinMax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset_encoded, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n",
    "\n",
    "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Unet by dividing encoder and decoder into blocks\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Activation, MaxPool2D, Concatenate\n",
    "\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)   #Not in the original network. \n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)  #Not in the original network\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "#Encoder block: Conv block followed by maxpooling\n",
    "\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p   \n",
    "\n",
    "#Decoder block\n",
    "#skip features gets input from encoder for concatenation\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "#Build Unet using the blocks\n",
    "def build_unet(input_shape, n_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024) #Bridge\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    if n_classes == 1:  #Binary\n",
    "      activation = 'sigmoid'\n",
    "    else:\n",
    "      activation = 'softmax'\n",
    "\n",
    "    outputs = Conv2D(n_classes, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n",
    "    print(activation)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = X_train.shape[1]\n",
    "IMG_WIDTH  = X_train.shape[2]\n",
    "IMG_CHANNELS = X_train.shape[3]\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_unet(input_shape, n_classes=n_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train_cat, \n",
    "                    batch_size = 16, \n",
    "                    verbose=1, \n",
    "                    epochs=5, \n",
    "                    validation_data=(X_test, y_test_cat), \n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model for future use\n",
    "model.save('./saved_models/unet.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        #Load previously saved model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"./saved_models/unet.hdf5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_argmax=np.argmax(y_pred, axis=3)\n",
    "y_pred_argmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using built in keras function\n",
    "# from keras.metrics import MeanIoU\n",
    "# n_classes = 1\n",
    "# IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "# IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\n",
    "# print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #To calculate I0U for each class...\n",
    "# values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\n",
    "# print(values)\n",
    "# class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])\n",
    "# class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])\n",
    "# class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])\n",
    "# class4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
    "\n",
    "# print(\"IoU for class1 is: \", class1_IoU)\n",
    "# print(\"IoU for class2 is: \", class2_IoU)\n",
    "# print(\"IoU for class3 is: \", class3_IoU)\n",
    "# print(\"IoU for class4 is: \", class4_IoU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on a few images\n",
    "#model = get_model()\n",
    "#model.load_weights('???.hdf5')\n",
    "import random\n",
    "test_img_number = random.randint(0, len(X_test)-1)\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth=y_test[test_img_number]\n",
    "test_img_norm=test_img[:,:,0][:,:,None]\n",
    "test_img_input=np.expand_dims(test_img_norm, 0)\n",
    "prediction = (model.predict(test_img_input))\n",
    "predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='jet')\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(predicted_img, cmap='jet')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
