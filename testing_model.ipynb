{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils import normalize\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tifffile as tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing images, if needed\n",
    "SIZE_X = 128 \n",
    "SIZE_Y = 128\n",
    "n_classes=4 #Number of classes for segmentation\n",
    "num_images = 200  #Total 1600 available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_names = glob.glob(\"E:/STUDY_MATERIALS/L4-T2/CSE 472/Unet/sandstone_data_for_ML/full_labels_for_deep_learning/128_patches/*.tif\")\n",
    "# print(len(image_names))\n",
    "# image_names.sort()\n",
    "# image_names_subset = image_names[0:num_images]\n",
    "# images = [cv2.imread(image, 0) for image in image_names_subset]\n",
    "# read tiff images\n",
    "images = tiff.imread(\"./PhC-C2DH-U373/01/*.tif\")\n",
    "# sort images by name\n",
    "images.sort()\n",
    "# select first 200 images\n",
    "images = images[0:num_images]\n",
    "image_dataset = np.array(images)\n",
    "image_dataset = np.expand_dims(image_dataset, axis = 3)\n",
    "print(image_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tiff.imread(\"./sandstone_data_for_ML/full_labels_for_deep_learning/128_patches/masks_as_128x128_patches.tif\")\n",
    "mask.sort()\n",
    "mask_subset = mask[0:num_images]\n",
    "\n",
    "mask_dataset = np.array(mask_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Image data shape is: \", image_dataset.shape)\n",
    "print(\"Mask data shape is: \", mask_dataset.shape)\n",
    "print(\"Max pixel value in image is: \", image_dataset.max())\n",
    "print(\"Labels in the mask are : \", np.unique(mask_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "import elasticdeform\n",
    "sigma = 30  # the standard deviation of the Gaussian filter\n",
    "alpha = 50  # the intensity of the deformation\n",
    "deformed_image = elasticdeform.deform_grid(image_dataset, sigma=sigma, alpha=alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode labels to 0, 1, 2, 3, ... but multi dim array so need to flatten, encode and reshape\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = mask_dataset.shape  \n",
    "mask_dataset_reshaped = mask_dataset.reshape(-1,1)\n",
    "mask_dataset_reshaped_encoded = labelencoder.fit_transform(mask_dataset_reshaped)\n",
    "mask_dataset_encoded = mask_dataset_reshaped_encoded.reshape(n, h, w)\n",
    "\n",
    "np.unique(mask_dataset_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dataset_encoded = np.expand_dims(mask_dataset_encoded, axis = 3)\n",
    "print(mask_dataset_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize images\n",
    "image_dataset = image_dataset /255.  #Can also normalize or scale using MinMax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset_encoded, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n",
    "\n",
    "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Unet by dividing encoder and decoder into blocks\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Activation, MaxPool2D, Concatenate\n",
    "\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)   #Not in the original network. \n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)  #Not in the original network\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "#Encoder block: Conv block followed by maxpooling\n",
    "\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p   \n",
    "\n",
    "#Decoder block\n",
    "#skip features gets input from encoder for concatenation\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "#Build Unet using the blocks\n",
    "def build_unet(input_shape, n_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024) #Bridge\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    if n_classes == 1:  #Binary\n",
    "      activation = 'sigmoid'\n",
    "    else:\n",
    "      activation = 'softmax'\n",
    "\n",
    "    outputs = Conv2D(n_classes, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n",
    "    print(activation)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Configure data path for celltracking data set PhC-C2DH-U373 and file structure\n",
    "path_dataset = \"./PhC-C2DH-U373/\"\n",
    "path_filestructure = \"./data\"\n",
    "\n",
    "# Initialize file structure\n",
    "if not os.path.exists(path_filestructure): os.mkdir(path_filestructure)\n",
    "\n",
    "# Iterate over both data sets\n",
    "for ds in [\"01\", \"02\"]:\n",
    "    # Define image directories\n",
    "    path_ds_img = os.path.join(path_dataset, ds)\n",
    "    path_ds_seg = os.path.join(path_dataset, ds + \"_GT\", \"SEG\")\n",
    "    # Obtain sample list\n",
    "    sample_list = os.listdir(path_ds_seg)\n",
    "    # Remove every file which does not match image typ and preprocess sample names\n",
    "    for i in reversed(range(0, len(sample_list))):\n",
    "        if not sample_list[i].endswith(\".tif\"):\n",
    "            del sample_list[i]\n",
    "        else:\n",
    "            sample_list[i] = sample_list[i][7:]\n",
    "    # Iterate over each sample and transform the data into desired file structure\n",
    "    for sample in sample_list:\n",
    "        index = ds + \"_\" + sample[:-4]\n",
    "        # Create sample directory\n",
    "        path_sampleDir = os.path.join(path_filestructure, index)\n",
    "        if not os.path.exists(path_sampleDir): os.mkdir(path_sampleDir)\n",
    "        # Copy image file into filestructure\n",
    "        path_ds_sample_img = os.path.join(path_ds_img, \"t\" + sample)\n",
    "        path_fs_sample_img = os.path.join(path_sampleDir, \"imaging.tif\")\n",
    "        shutil.copy(path_ds_sample_img, path_fs_sample_img)\n",
    "        # Copy segmentation file into filestructure\n",
    "        seg_file = \"man_seg\" + sample\n",
    "        path_ds_sample_seg = os.path.join(path_ds_seg, seg_file)\n",
    "        path_fs_sample_seg = os.path.join(path_sampleDir, \"segmentation.tif\")\n",
    "        # Load segmentation from file\n",
    "        seg_raw = Image.open(path_ds_sample_seg)\n",
    "        # Convert segmentation from Pillow image to numpy matrix\n",
    "        seg_pil = seg_raw.convert(\"LA\")\n",
    "        seg = np.array(seg_pil)\n",
    "        # Keep only intensity and remove maximum intensitiy range\n",
    "        seg_data = seg[:,:,0]\n",
    "        # Union all separate cell classes to a single one\n",
    "        seg_data[seg_data > 0] = 1\n",
    "        # Transform numpy array back to a Pillow image & save to disk\n",
    "        seg = Image.fromarray(seg_data)\n",
    "        seg.save(path_fs_sample_seg, format=\"TIFF\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
